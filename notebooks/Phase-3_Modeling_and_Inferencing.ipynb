{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Phase 3: Modeling & Inferencing\n",
    "\n",
    "**Team**: The Outliers  \n",
    "**Course**: Advanced Apex Project 1 - BITS Pilani Digital  \n",
    "**Phase**: 3 (Model Construction & Evaluation)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ What are we doing in Phase 3?\n",
    "\n",
    "We are building **regression models** to predict house prices (`SalePrice`) using the features we engineered in Phase 2.\n",
    "\n",
    "## ğŸ¤” Why are we doing this?\n",
    "\n",
    "- To **predict house prices accurately** for properties in Ames, Iowa\n",
    "- To **understand which features** most influence property values\n",
    "- To **compare different modeling approaches** (Simple vs Multiple Linear Regression)\n",
    "- To **measure model performance** using statistical metrics\n",
    "\n",
    "## ğŸ“Š Models to Build (as per Phase 3 requirements):\n",
    "\n",
    "1. **Simple Linear Regression**: Uses ONE best feature to predict price\n",
    "2. **Multiple Linear Regression**: Uses ALL features to predict price\n",
    "\n",
    "## ğŸ“ Evaluation Metrics:\n",
    "\n",
    "- **RÂ² (R-squared)**: How much variance in price our model explains (0 to 1, higher is better)\n",
    "- **RMSE (Root Mean Squared Error)**: Average prediction error in dollars (lower is better)\n",
    "- **MAE (Mean Absolute Error)**: Average absolute error in dollars (lower is better)\n",
    "\n",
    "## ğŸ”® Expected Results:\n",
    "\n",
    "From Phase 2, we know `Overall Qual` has 0.80 correlation with price:\n",
    "- Simple LR should achieve RÂ² â‰ˆ 0.64\n",
    "- Multiple LR should achieve RÂ² > 0.70\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## Step 1: Setup & Import Libraries\n",
    "\n",
    "### ğŸ¯ What are we doing?\n",
    "Importing all necessary Python libraries for data manipulation, machine learning, and visualization.\n",
    "\n",
    "### ğŸ¤” Why these libraries?\n",
    "- **pandas**: Load and work with datasets\n",
    "- **numpy**: Mathematical operations\n",
    "- **scikit-learn**: Build and evaluate machine learning models\n",
    "- **matplotlib/seaborn**: Create visualizations\n",
    "\n",
    "### ğŸ“Š Expected Result:\n",
    "All libraries should import successfully with no errors.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T07:49:55.053877Z",
     "iopub.status.busy": "2025-11-23T07:49:55.052260Z",
     "iopub.status.idle": "2025-11-23T07:49:56.658984Z",
     "shell.execute_reply": "2025-11-23T07:49:56.657680Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries imported successfully!\n",
      "ğŸ“¦ Pandas version: 2.3.3\n",
      "ğŸ“¦ NumPy version: 2.2.6\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Settings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"âœ… Libraries imported successfully!\")\n",
    "print(f\"ğŸ“¦ Pandas version: {pd.__version__}\")\n",
    "print(f\"ğŸ“¦ NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-data-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 2: Load Engineered Dataset\n",
    "\n",
    "### ğŸ¯ What are we doing?\n",
    "Loading the **engineered dataset** from Phase 2C (`AmesHousing_engineered.csv`).\n",
    "\n",
    "### ğŸ¤” Why this specific dataset?\n",
    "This dataset contains:\n",
    "- âœ… All missing values handled (imputed)\n",
    "- âœ… All categorical features encoded (converted to numbers)\n",
    "- âœ… New engineered features (Total_SF, Total_Bathrooms, etc.)\n",
    "- âœ… Log-transformed skewed features for better modeling\n",
    "- âœ… Multicollinearity reduced (highly correlated features removed)\n",
    "\n",
    "### ğŸ“Š Expected Result:\n",
    "- Dataset shape: **(2,930 rows Ã— 71 columns)**\n",
    "- Target variable: `SalePrice` (house prices in dollars)\n",
    "- All features should be numeric (ready for machine learning)\n",
    "- Minimal to no missing values\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "load-data",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T07:49:56.662045Z",
     "iopub.status.busy": "2025-11-23T07:49:56.661487Z",
     "iopub.status.idle": "2025-11-23T07:49:56.708668Z",
     "shell.execute_reply": "2025-11-23T07:49:56.707616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset loaded successfully!\n",
      "\n",
      "ğŸ“Š Dataset Shape: (2930, 71)\n",
      "   - Total Records (Houses): 2,930\n",
      "   - Total Features (Columns): 71\n",
      "\n",
      "â“ Missing Values: 3\n",
      "   âš ï¸ Warning: Found 3 missing values - need to handle these\n",
      "\n",
      "ğŸ“‹ Data Types:\n",
      "int64      58\n",
      "float64    13\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ğŸ“‹ First 3 rows of the dataset:\n",
      "   Order        PID  MS SubClass  MS Zoning  Lot Frontage  Lot Area  \\\n",
      "0      1  526301100           20          5        141.00     31770   \n",
      "1      2  526350040           20          4         80.00     11622   \n",
      "2      3  526351010           20          5         81.00     14267   \n",
      "\n",
      "   Lot Shape  Land Contour  Lot Config  Neighborhood  Condition 1  Bldg Type  \\\n",
      "0          0             3           0            15            2          0   \n",
      "1          3             3           4            15            1          0   \n",
      "2          0             3           0            15            2          0   \n",
      "\n",
      "   House Style  Overall Qual  Overall Cond  Year Built  Year Remod/Add  \\\n",
      "0            2             6             5        1960            1960   \n",
      "1            2             5             6        1961            1961   \n",
      "2            2             6             6        1958            1958   \n",
      "\n",
      "   Roof Style  Exterior 1st  Mas Vnr Type  Mas Vnr Area  Exter Qual  \\\n",
      "0           3             3             4        112.00           3   \n",
      "1           1            13             3          0.00           3   \n",
      "2           3            14             1        108.00           3   \n",
      "\n",
      "   Exter Cond  Foundation  Bsmt Qual  Bsmt Cond  Bsmt Exposure  \\\n",
      "0           3           1          3          4              1   \n",
      "1           3           1          3          3              3   \n",
      "2           3           1          3          3              3   \n",
      "\n",
      "   BsmtFin Type 1  BsmtFin SF 1  BsmtFin Type 2  BsmtFin SF 2  Bsmt Unf SF  \\\n",
      "0               1        639.00               6          0.00       441.00   \n",
      "1               5        468.00               3        144.00       270.00   \n",
      "2               0        923.00               6          0.00       406.00   \n",
      "\n",
      "   Total Bsmt SF  Heating QC  Central Air  Electrical  1st Flr SF  2nd Flr SF  \\\n",
      "0        1080.00           2            1           4        1656           0   \n",
      "1         882.00           3            1           4         896           0   \n",
      "2        1329.00           3            1           4        1329           0   \n",
      "\n",
      "   Low Qual Fin SF  Gr Liv Area  Bsmt Full Bath  Bsmt Half Bath  Full Bath  \\\n",
      "0                0         1656            1.00            0.00          1   \n",
      "1                0          896            0.00            0.00          1   \n",
      "2                0         1329            0.00            0.00          1   \n",
      "\n",
      "   Half Bath  Bedroom AbvGr  Kitchen AbvGr  Kitchen Qual  TotRms AbvGrd  \\\n",
      "0          0              3              1             3              7   \n",
      "1          0              2              1             3              5   \n",
      "2          1              3              1             4              6   \n",
      "\n",
      "   Functional  Fireplaces  Garage Type  Garage Yr Blt  Garage Finish  \\\n",
      "0           7           2            1        1960.00              0   \n",
      "1           7           0            1        1961.00              3   \n",
      "2           7           0            1        1958.00              3   \n",
      "\n",
      "   Garage Cars  Paved Drive  Wood Deck SF  Open Porch SF  Enclosed Porch  \\\n",
      "0         2.00            1           210             62               0   \n",
      "1         1.00            2           140              0               0   \n",
      "2         1.00            2           393             36               0   \n",
      "\n",
      "   3Ssn Porch  Screen Porch  Pool Area  Misc Val  Mo Sold  Yr Sold  Sale Type  \\\n",
      "0           0             0          0         0        5     2010          9   \n",
      "1           0           120          0         0        6     2010          9   \n",
      "2           0             0          0     12500        6     2010          9   \n",
      "\n",
      "   Sale Condition  SalePrice  Total_Bathrooms  Total_Porch_SF  Lot Area_Log  \\\n",
      "0               4     215000             2.00              62         10.37   \n",
      "1               4     105000             1.00             120          9.36   \n",
      "2               4     172000             1.50              36          9.57   \n",
      "\n",
      "   SalePrice_Log  \n",
      "0          12.28  \n",
      "1          11.56  \n",
      "2          12.06  \n"
     ]
    }
   ],
   "source": [
    "# Load the engineered dataset from Phase 2C\n",
    "df = pd.read_csv(\"../data/AmesHousing_engineered.csv\")\n",
    "\n",
    "print(\"âœ… Dataset loaded successfully!\")\n",
    "print(f\"\\nğŸ“Š Dataset Shape: {df.shape}\")\n",
    "print(f\"   - Total Records (Houses): {df.shape[0]:,}\")\n",
    "print(f\"   - Total Features (Columns): {df.shape[1]}\")\n",
    "\n",
    "# Check for missing values\n",
    "missing_count = df.isnull().sum().sum()\n",
    "print(f\"\\nâ“ Missing Values: {missing_count}\")\n",
    "if missing_count > 0:\n",
    "    print(f\"   âš ï¸ Warning: Found {missing_count} missing values - need to handle these\")\n",
    "else:\n",
    "    print(\"   âœ… No missing values - dataset is complete!\")\n",
    "\n",
    "# Check data types\n",
    "print(f\"\\nğŸ“‹ Data Types:\")\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nğŸ“‹ First 3 rows of the dataset:\")\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "z9gzkxe635",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Investigate Missing Values\n",
    "\n",
    "### ğŸ¯ What are we doing?\n",
    "Identifying exactly WHERE the 3 missing values are located (which columns and rows).\n",
    "\n",
    "### ğŸ¤” Why investigate first?\n",
    "Before handling missing values, we need to understand:\n",
    "- Which features contain missing data\n",
    "- How many missing values per feature\n",
    "- Whether these are critical features for modeling\n",
    "\n",
    "### ğŸ“Š Expected Result:\n",
    "- List of columns with missing values\n",
    "- Count of missing values per column\n",
    "- Decision on how to handle them (drop, impute, or investigate)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9gg25rq5onu",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T07:49:56.711520Z",
     "iopub.status.busy": "2025-11-23T07:49:56.711218Z",
     "iopub.status.idle": "2025-11-23T07:49:56.724676Z",
     "shell.execute_reply": "2025-11-23T07:49:56.723566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Columns with Missing Values:\n",
      "==================================================\n",
      "   â€¢ Lot Frontage: 3 missing (0.10%)\n",
      "\n",
      "ğŸ“Š Total missing values: 3\n",
      "\n",
      "ğŸ“‹ Rows containing missing values:\n",
      "      Lot Frontage\n",
      "2256           NaN\n",
      "2788           NaN\n",
      "2892           NaN\n",
      "\n",
      "âœ… Dataset Completeness: 99.9986%\n"
     ]
    }
   ],
   "source": [
    "# Identify columns with missing values\n",
    "missing_by_column = df.isnull().sum()\n",
    "missing_features = missing_by_column[missing_by_column > 0]\n",
    "\n",
    "print(\"ğŸ” Columns with Missing Values:\")\n",
    "print(\"=\"*50)\n",
    "if len(missing_features) > 0:\n",
    "    for col, count in missing_features.items():\n",
    "        percentage = (count / len(df)) * 100\n",
    "        print(f\"   â€¢ {col}: {count} missing ({percentage:.2f}%)\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Total missing values: {missing_features.sum()}\")\n",
    "    \n",
    "    # Show the rows with missing values\n",
    "    print(f\"\\nğŸ“‹ Rows containing missing values:\")\n",
    "    missing_rows = df[df.isnull().any(axis=1)]\n",
    "    print(missing_rows[missing_features.index.tolist()].head(10))\n",
    "else:\n",
    "    print(\"   âœ… No missing values found!\")\n",
    "\n",
    "# Check data completeness\n",
    "completeness = (1 - df.isnull().sum().sum() / (df.shape[0] * df.shape[1])) * 100\n",
    "print(f\"\\nâœ… Dataset Completeness: {completeness:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s3ajndq6dc",
   "metadata": {},
   "source": [
    "### ğŸ” Analysis of Missing Values\n",
    "\n",
    "**Finding**: All 3 missing values are in `Lot Frontage` column\n",
    "\n",
    "**Context**:\n",
    "- `Lot Frontage` = Linear feet of street connected to property\n",
    "- Only 0.10% of data missing (3 out of 2,930 rows)\n",
    "- Dataset is 99.9986% complete\n",
    "\n",
    "**Next Step**: Investigate these 3 rows to understand their characteristics before deciding on handling strategy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aasdg0yg16b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T07:49:56.727498Z",
     "iopub.status.busy": "2025-11-23T07:49:56.727168Z",
     "iopub.status.idle": "2025-11-23T07:49:56.744389Z",
     "shell.execute_reply": "2025-11-23T07:49:56.743300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ Detailed view of rows with missing Lot Frontage:\n",
      "======================================================================\n",
      "      Order        PID  Neighborhood  Lot Area  Lot Frontage  Gr Liv Area  \\\n",
      "2256   2257  916253320            10      9763           NaN         1502   \n",
      "2788   2789  907230240            12      3612           NaN         1320   \n",
      "2892   2893  916252170            10      8239           NaN         1295   \n",
      "\n",
      "      Overall Qual  SalePrice  \n",
      "2256             7     330000  \n",
      "2788             6     137000  \n",
      "2892             7     230000  \n",
      "\n",
      "\n",
      "ğŸ“Š Lot Frontage Statistics (for context):\n",
      "======================================================================\n",
      "count   2927.00\n",
      "mean      69.46\n",
      "std       21.73\n",
      "min       21.00\n",
      "25%       60.00\n",
      "50%       70.00\n",
      "75%       80.00\n",
      "max      313.00\n",
      "Name: Lot Frontage, dtype: float64\n",
      "\n",
      "\n",
      "ğŸ˜ï¸ Neighborhoods of rows with missing values:\n",
      "======================================================================\n",
      "   Row 2256: Neighborhood Code = 10\n",
      "   Row 2788: Neighborhood Code = 12\n",
      "   Row 2892: Neighborhood Code = 10\n",
      "\n",
      "\n",
      "ğŸ“ Lot Frontage Median for these neighborhoods:\n",
      "======================================================================\n",
      "   Neighborhood 10: Median = nan feet\n",
      "   Neighborhood 12: Median = nan feet\n",
      "   Neighborhood 10: Median = nan feet\n"
     ]
    }
   ],
   "source": [
    "# Get the 3 rows with missing Lot Frontage\n",
    "missing_indices = [2256, 2788, 2892]\n",
    "missing_details = df.loc[missing_indices]\n",
    "\n",
    "print(\"ğŸ“‹ Detailed view of rows with missing Lot Frontage:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Show key identifying features\n",
    "key_features = ['Order', 'PID', 'Neighborhood', 'Lot Area', 'Lot Frontage', \n",
    "                'Gr Liv Area', 'Overall Qual', 'SalePrice']\n",
    "\n",
    "print(missing_details[key_features])\n",
    "\n",
    "# Get statistics for Lot Frontage to understand typical values\n",
    "print(\"\\n\\nğŸ“Š Lot Frontage Statistics (for context):\")\n",
    "print(\"=\"*70)\n",
    "print(df['Lot Frontage'].describe())\n",
    "\n",
    "# Check neighborhoods of missing rows\n",
    "print(\"\\n\\nğŸ˜ï¸ Neighborhoods of rows with missing values:\")\n",
    "print(\"=\"*70)\n",
    "for idx in missing_indices:\n",
    "    neighborhood = df.loc[idx, 'Neighborhood']\n",
    "    print(f\"   Row {idx}: Neighborhood Code = {neighborhood}\")\n",
    "\n",
    "# Show Lot Frontage median by neighborhood for these specific neighborhoods\n",
    "print(\"\\n\\nğŸ“ Lot Frontage Median for these neighborhoods:\")\n",
    "print(\"=\"*70)\n",
    "for idx in missing_indices:\n",
    "    neighborhood = df.loc[idx, 'Neighborhood']\n",
    "    neighborhood_median = df[df['Neighborhood'] == neighborhood]['Lot Frontage'].median()\n",
    "    print(f\"   Neighborhood {neighborhood}: Median = {neighborhood_median:.2f} feet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oa8lbu1gm7",
   "metadata": {},
   "source": [
    "### âš ï¸ Issue Found: Neighborhood median calculation returned NaN\n",
    "\n",
    "**Problem**: Need to properly calculate median by excluding NaN values\n",
    "\n",
    "**Next**: Re-calculate neighborhood statistics correctly and determine best imputation strategy\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "qgvkrrf2qog",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T07:49:56.747198Z",
     "iopub.status.busy": "2025-11-23T07:49:56.746770Z",
     "iopub.status.idle": "2025-11-23T07:49:56.760676Z",
     "shell.execute_reply": "2025-11-23T07:49:56.758983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Proper Neighborhood Analysis:\n",
      "======================================================================\n",
      "\n",
      "ğŸ“ Row 2256 (Neighborhood 10):\n",
      "   âš ï¸ No other properties in this neighborhood have Lot Frontage data!\n",
      "   Need to use overall median instead\n",
      "\n",
      "ğŸ“ Row 2788 (Neighborhood 12):\n",
      "   âš ï¸ No other properties in this neighborhood have Lot Frontage data!\n",
      "   Need to use overall median instead\n",
      "\n",
      "ğŸ“ Row 2892 (Neighborhood 10):\n",
      "   âš ï¸ No other properties in this neighborhood have Lot Frontage data!\n",
      "   Need to use overall median instead\n",
      "\n",
      "\n",
      "ğŸ“Š Overall Dataset Statistics (for fallback):\n",
      "======================================================================\n",
      "   Median Lot Frontage: 70.00 feet\n",
      "   Mean Lot Frontage: 69.46 feet\n"
     ]
    }
   ],
   "source": [
    "# Properly investigate neighborhoods with missing values\n",
    "print(\"ğŸ” Proper Neighborhood Analysis:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for idx in missing_indices:\n",
    "    neighborhood = df.loc[idx, 'Neighborhood']\n",
    "    lot_area = df.loc[idx, 'Lot Area']\n",
    "    \n",
    "    # Get all properties in this neighborhood (excluding current row)\n",
    "    neighborhood_data = df[(df['Neighborhood'] == neighborhood) & (df.index != idx)]\n",
    "    \n",
    "    # Count properties in neighborhood\n",
    "    total_in_neighborhood = len(neighborhood_data)\n",
    "    \n",
    "    # Get Lot Frontage values (excluding NaN)\n",
    "    lot_frontage_values = neighborhood_data['Lot Frontage'].dropna()\n",
    "    count_with_frontage = len(lot_frontage_values)\n",
    "    \n",
    "    # Calculate median (properly, excluding NaN)\n",
    "    if count_with_frontage > 0:\n",
    "        median_frontage = lot_frontage_values.median()\n",
    "        mean_frontage = lot_frontage_values.mean()\n",
    "        \n",
    "        print(f\"\\nğŸ“ Row {idx} (Neighborhood {neighborhood}):\")\n",
    "        print(f\"   - Total properties in neighborhood: {total_in_neighborhood}\")\n",
    "        print(f\"   - Properties with Lot Frontage data: {count_with_frontage}\")\n",
    "        print(f\"   - Median Lot Frontage: {median_frontage:.2f} feet\")\n",
    "        print(f\"   - Mean Lot Frontage: {mean_frontage:.2f} feet\")\n",
    "        print(f\"   - This property's Lot Area: {lot_area:,.0f} sq ft\")\n",
    "    else:\n",
    "        print(f\"\\nğŸ“ Row {idx} (Neighborhood {neighborhood}):\")\n",
    "        print(f\"   âš ï¸ No other properties in this neighborhood have Lot Frontage data!\")\n",
    "        print(f\"   Need to use overall median instead\")\n",
    "\n",
    "# Calculate overall median (excluding NaN) as fallback\n",
    "overall_median = df['Lot Frontage'].median()\n",
    "overall_mean = df['Lot Frontage'].mean()\n",
    "\n",
    "print(f\"\\n\\nğŸ“Š Overall Dataset Statistics (for fallback):\")\n",
    "print(\"=\"*70)\n",
    "print(f\"   Median Lot Frontage: {overall_median:.2f} feet\")\n",
    "print(f\"   Mean Lot Frontage: {overall_mean:.2f} feet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ssr7vzantl",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 4: Handle Missing Values\n",
    "\n",
    "### ğŸ¯ What are we doing?\n",
    "Imputing the 3 missing `Lot Frontage` values using the **overall median** (70.00 feet).\n",
    "\n",
    "### ğŸ¤” Why overall median instead of neighborhood median?\n",
    "- **Problem**: Neighborhoods 10 and 12 have NO other properties with Lot Frontage data\n",
    "- **Solution**: Use the overall dataset median as the most reasonable estimate\n",
    "- **Median vs Mean**: Using median (70.00) instead of mean (69.46) because median is more robust to outliers\n",
    "\n",
    "### ğŸ“Š Expected Result:\n",
    "- All 3 missing values filled with 70.00 feet\n",
    "- Zero missing values in dataset\n",
    "- Dataset ready for machine learning\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "l8ozp69gf9i",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T07:49:56.764077Z",
     "iopub.status.busy": "2025-11-23T07:49:56.763763Z",
     "iopub.status.idle": "2025-11-23T07:49:56.778488Z",
     "shell.execute_reply": "2025-11-23T07:49:56.777405Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Imputing Missing Lot Frontage Values:\n",
      "======================================================================\n",
      "Missing values BEFORE imputation: 3\n",
      "Imputation value (overall median): 70.00 feet\n",
      "\n",
      "Rows to be imputed: [2256, 2788, 2892]\n",
      "\n",
      "Missing values AFTER imputation: 0\n",
      "\n",
      "âœ… Total missing values in entire dataset: 0\n",
      "   ğŸ‰ SUCCESS! Dataset is now 100% complete and ready for modeling!\n",
      "\n",
      "ğŸ“‹ Imputed values verification:\n",
      "      Order  Neighborhood  Lot Area  Lot Frontage  SalePrice\n",
      "2256   2257            10      9763         70.00     330000\n",
      "2788   2789            12      3612         70.00     137000\n",
      "2892   2893            10      8239         70.00     230000\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values by imputing with overall median\n",
    "print(\"ğŸ”§ Imputing Missing Lot Frontage Values:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Store original count of missing values\n",
    "original_missing = df['Lot Frontage'].isnull().sum()\n",
    "print(f\"Missing values BEFORE imputation: {original_missing}\")\n",
    "\n",
    "# Calculate overall median\n",
    "overall_median = df['Lot Frontage'].median()\n",
    "print(f\"Imputation value (overall median): {overall_median:.2f} feet\")\n",
    "\n",
    "# Show which rows will be imputed\n",
    "missing_indices = df[df['Lot Frontage'].isnull()].index.tolist()\n",
    "print(f\"\\nRows to be imputed: {missing_indices}\")\n",
    "\n",
    "# Perform imputation\n",
    "df['Lot Frontage'].fillna(overall_median, inplace=True)\n",
    "\n",
    "# Verify imputation\n",
    "remaining_missing = df['Lot Frontage'].isnull().sum()\n",
    "print(f\"\\nMissing values AFTER imputation: {remaining_missing}\")\n",
    "\n",
    "# Verify total dataset completeness\n",
    "total_missing = df.isnull().sum().sum()\n",
    "print(f\"\\nâœ… Total missing values in entire dataset: {total_missing}\")\n",
    "\n",
    "if total_missing == 0:\n",
    "    print(\"   ğŸ‰ SUCCESS! Dataset is now 100% complete and ready for modeling!\")\n",
    "else:\n",
    "    print(f\"   âš ï¸ Warning: {total_missing} missing values still remain\")\n",
    "\n",
    "# Show the imputed values\n",
    "print(f\"\\nğŸ“‹ Imputed values verification:\")\n",
    "print(df.loc[missing_indices, ['Order', 'Neighborhood', 'Lot Area', 'Lot Frontage', 'SalePrice']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "itkr23sbu8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 5: Prepare Features and Target Variable\n",
    "\n",
    "### ğŸ¯ What are we doing?\n",
    "Separating the dataset into **features (X)** and **target variable (y)** for modeling.\n",
    "\n",
    "### ğŸ¤” Key Decisions:\n",
    "- **Target Variable**: Use `SalePrice` (original price in dollars), not `SalePrice_Log`\n",
    "- **Features**: All columns EXCEPT identifiers (`Order`, `PID`) and target variables\n",
    "- **Columns to Exclude**: Order, PID, SalePrice, SalePrice_Log, Lot Area_Log (redundant with Lot Area)\n",
    "\n",
    "### ğŸ“Š Expected Result:\n",
    "- **X**: Feature matrix with ~66 features (all numeric)\n",
    "- **y**: Target vector with 2,930 house prices\n",
    "- Ready for train-test split\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fl1n5ac7uss",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T07:49:56.781404Z",
     "iopub.status.busy": "2025-11-23T07:49:56.780853Z",
     "iopub.status.idle": "2025-11-23T07:49:56.793572Z",
     "shell.execute_reply": "2025-11-23T07:49:56.792448Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Preparing Features and Target Variable:\n",
      "======================================================================\n",
      "Columns to exclude: ['Order', 'PID', 'SalePrice', 'SalePrice_Log', 'Lot Area_Log']\n",
      "\n",
      "âœ… Features (X):\n",
      "   - Shape: (2930, 66)\n",
      "   - Total features: 66\n",
      "   - Total records: 2,930\n",
      "\n",
      "âœ… Target (y):\n",
      "   - Shape: (2930,)\n",
      "   - Total records: 2,930\n",
      "   - Min price: $12,789\n",
      "   - Max price: $755,000\n",
      "   - Mean price: $180,796\n",
      "   - Median price: $160,000\n",
      "\n",
      "ğŸ“‹ Feature names (first 10):\n",
      "   1. MS SubClass\n",
      "   2. MS Zoning\n",
      "   3. Lot Frontage\n",
      "   4. Lot Area\n",
      "   5. Lot Shape\n",
      "   6. Land Contour\n",
      "   7. Lot Config\n",
      "   8. Neighborhood\n",
      "   9. Condition 1\n",
      "   10. Bldg Type\n",
      "   ... and 56 more features\n",
      "\n",
      "ğŸ” Data Quality Check:\n",
      "   Missing values in X: 0\n",
      "   Missing values in y: 0\n",
      "   âœ… Data is ready for modeling!\n"
     ]
    }
   ],
   "source": [
    "# Prepare features and target variable\n",
    "print(\"ğŸ”§ Preparing Features and Target Variable:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Define columns to exclude (identifiers and target variables)\n",
    "columns_to_exclude = ['Order', 'PID', 'SalePrice', 'SalePrice_Log', 'Lot Area_Log']\n",
    "\n",
    "print(f\"Columns to exclude: {columns_to_exclude}\")\n",
    "\n",
    "# Create feature matrix X (all columns except excluded ones)\n",
    "X = df.drop(columns=columns_to_exclude)\n",
    "\n",
    "# Create target vector y (SalePrice in dollars)\n",
    "y = df['SalePrice']\n",
    "\n",
    "print(f\"\\nâœ… Features (X):\")\n",
    "print(f\"   - Shape: {X.shape}\")\n",
    "print(f\"   - Total features: {X.shape[1]}\")\n",
    "print(f\"   - Total records: {X.shape[0]:,}\")\n",
    "\n",
    "print(f\"\\nâœ… Target (y):\")\n",
    "print(f\"   - Shape: {y.shape}\")\n",
    "print(f\"   - Total records: {y.shape[0]:,}\")\n",
    "print(f\"   - Min price: ${y.min():,.0f}\")\n",
    "print(f\"   - Max price: ${y.max():,.0f}\")\n",
    "print(f\"   - Mean price: ${y.mean():,.0f}\")\n",
    "print(f\"   - Median price: ${y.median():,.0f}\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ Feature names (first 10):\")\n",
    "for i, col in enumerate(X.columns[:10], 1):\n",
    "    print(f\"   {i}. {col}\")\n",
    "\n",
    "print(f\"   ... and {X.shape[1] - 10} more features\")\n",
    "\n",
    "# Verify no missing values in X and y\n",
    "print(f\"\\nğŸ” Data Quality Check:\")\n",
    "print(f\"   Missing values in X: {X.isnull().sum().sum()}\")\n",
    "print(f\"   Missing values in y: {y.isnull().sum()}\")\n",
    "print(f\"   âœ… Data is ready for modeling!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s5aqhui7mw9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 6: Train-Test Split\n",
    "\n",
    "### ğŸ¯ What are we doing?\n",
    "Splitting the dataset into **training set** (80%) and **testing set** (20%).\n",
    "\n",
    "### ğŸ¤” Why split the data?\n",
    "- **Training set**: Used to build/train our regression models\n",
    "- **Testing set**: Used to evaluate model performance on unseen data\n",
    "- **80-20 split**: Standard practice that balances training data volume with testing reliability\n",
    "- **random_state=42**: Ensures reproducibility (same split every time we run)\n",
    "\n",
    "### ğŸ“Š Expected Result:\n",
    "- X_train: 2,344 samples (80%)\n",
    "- X_test: 586 samples (20%)\n",
    "- y_train: 2,344 prices\n",
    "- y_test: 586 prices\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "r9d302fc83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T07:49:56.796257Z",
     "iopub.status.busy": "2025-11-23T07:49:56.795874Z",
     "iopub.status.idle": "2025-11-23T07:49:56.809721Z",
     "shell.execute_reply": "2025-11-23T07:49:56.808592Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Splitting Data into Train and Test Sets:\n",
      "======================================================================\n",
      "âœ… Training Set:\n",
      "   - X_train shape: (2344, 66)\n",
      "   - y_train shape: (2344,)\n",
      "   - Number of samples: 2,344 (80.0%)\n",
      "   - Number of features: 66\n",
      "\n",
      "âœ… Testing Set:\n",
      "   - X_test shape: (586, 66)\n",
      "   - y_test shape: (586,)\n",
      "   - Number of samples: 586 (20.0%)\n",
      "   - Number of features: 66\n",
      "\n",
      "ğŸ“Š Target Variable Statistics:\n",
      "\n",
      "   Training Set (y_train):\n",
      "      - Mean price: $178,582\n",
      "      - Median price: $160,000\n",
      "      - Min price: $12,789\n",
      "      - Max price: $755,000\n",
      "\n",
      "   Testing Set (y_test):\n",
      "      - Mean price: $189,651\n",
      "      - Median price: $165,000\n",
      "      - Min price: $44,000\n",
      "      - Max price: $625,000\n",
      "\n",
      "âœ… Data split complete! Ready to build models.\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing sets\n",
    "print(\"ğŸ”§ Splitting Data into Train and Test Sets:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Perform train-test split (80-20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.20,      # 20% for testing\n",
    "    random_state=42      # For reproducibility\n",
    ")\n",
    "\n",
    "print(f\"âœ… Training Set:\")\n",
    "print(f\"   - X_train shape: {X_train.shape}\")\n",
    "print(f\"   - y_train shape: {y_train.shape}\")\n",
    "print(f\"   - Number of samples: {X_train.shape[0]:,} ({(X_train.shape[0]/len(X))*100:.1f}%)\")\n",
    "print(f\"   - Number of features: {X_train.shape[1]}\")\n",
    "\n",
    "print(f\"\\nâœ… Testing Set:\")\n",
    "print(f\"   - X_test shape: {X_test.shape}\")\n",
    "print(f\"   - y_test shape: {y_test.shape}\")\n",
    "print(f\"   - Number of samples: {X_test.shape[0]:,} ({(X_test.shape[0]/len(X))*100:.1f}%)\")\n",
    "print(f\"   - Number of features: {X_test.shape[1]}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Target Variable Statistics:\")\n",
    "print(f\"\\n   Training Set (y_train):\")\n",
    "print(f\"      - Mean price: ${y_train.mean():,.0f}\")\n",
    "print(f\"      - Median price: ${y_train.median():,.0f}\")\n",
    "print(f\"      - Min price: ${y_train.min():,.0f}\")\n",
    "print(f\"      - Max price: ${y_train.max():,.0f}\")\n",
    "\n",
    "print(f\"\\n   Testing Set (y_test):\")\n",
    "print(f\"      - Mean price: ${y_test.mean():,.0f}\")\n",
    "print(f\"      - Median price: ${y_test.median():,.0f}\")\n",
    "print(f\"      - Min price: ${y_test.min():,.0f}\")\n",
    "print(f\"      - Max price: ${y_test.max():,.0f}\")\n",
    "\n",
    "print(f\"\\nâœ… Data split complete! Ready to build models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "igs6guxmy2r",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 7: Simple Linear Regression Model\n",
    "\n",
    "### ğŸ¯ What are we doing?\n",
    "Building a **Simple Linear Regression** model using the **ONE best feature** to predict house prices.\n",
    "\n",
    "### ğŸ¤” Why Simple Linear Regression first?\n",
    "- Establishes a **baseline** for model performance\n",
    "- Shows how much predictive power a single feature has\n",
    "- Easy to interpret and visualize\n",
    "- From Phase 2, we know `Overall Qual` has the strongest correlation (0.80)\n",
    "\n",
    "### ğŸ“Š Expected Result:\n",
    "- Identify the best single feature (highest correlation with SalePrice)\n",
    "- Build Simple LR model using only that feature\n",
    "- Expected RÂ² â‰ˆ 0.64 (correlationÂ² = 0.80Â² â‰ˆ 0.64)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "qb6u0k2fzq",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T07:49:56.812415Z",
     "iopub.status.busy": "2025-11-23T07:49:56.812016Z",
     "iopub.status.idle": "2025-11-23T07:49:56.853919Z",
     "shell.execute_reply": "2025-11-23T07:49:56.852525Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Identifying the Best Single Feature for Simple Linear Regression:\n",
      "======================================================================\n",
      "ğŸ“Š Top 10 Features by Correlation with SalePrice:\n",
      "======================================================================\n",
      "    1. Overall Qual              : 0.7953\n",
      "    2. Gr Liv Area               : 0.6983\n",
      "    3. Exter Qual                : 0.6853\n",
      "    4. Kitchen Qual              : 0.6612\n",
      "    5. Garage Cars               : 0.6439\n",
      "    6. Total_Bathrooms           : 0.6391\n",
      "    7. Total Bsmt SF             : 0.6126\n",
      "    8. 1st Flr SF                : 0.6074\n",
      "    9. Bsmt Qual                 : 0.6016\n",
      "   10. Year Built                : 0.5454\n",
      "\n",
      "âœ… Best Single Feature Selected:\n",
      "   Feature: Overall Qual\n",
      "   Correlation: 0.7953\n",
      "   Expected RÂ²: 0.6325 (correlationÂ²)\n",
      "\n",
      "ğŸ“‹ This feature will be used for Simple Linear Regression\n"
     ]
    }
   ],
   "source": [
    "# Step 7a: Identify the best single feature\n",
    "print(\"ğŸ” Identifying the Best Single Feature for Simple Linear Regression:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Calculate correlations between all features and target variable\n",
    "correlations = X_train.corrwith(y_train).abs().sort_values(ascending=False)\n",
    "\n",
    "print(f\"ğŸ“Š Top 10 Features by Correlation with SalePrice:\")\n",
    "print(\"=\"*70)\n",
    "for i, (feature, corr) in enumerate(correlations.head(10).items(), 1):\n",
    "    print(f\"   {i:2d}. {feature:25s} : {corr:.4f}\")\n",
    "\n",
    "# Select the best feature\n",
    "best_feature = correlations.index[0]\n",
    "best_correlation = correlations.iloc[0]\n",
    "\n",
    "print(f\"\\nâœ… Best Single Feature Selected:\")\n",
    "print(f\"   Feature: {best_feature}\")\n",
    "print(f\"   Correlation: {best_correlation:.4f}\")\n",
    "print(f\"   Expected RÂ²: {best_correlation**2:.4f} (correlationÂ²)\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ This feature will be used for Simple Linear Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aje7dq6nt6u",
   "metadata": {},
   "source": [
    "### ğŸ“ˆ Step 7b: Build and Train Simple Linear Regression\n",
    "\n",
    "**What we're doing**: Training the model using only `Overall Qual` to predict `SalePrice`\n",
    "\n",
    "**Model equation**: `SalePrice = Î²â‚€ + Î²â‚ Ã— Overall_Qual`\n",
    "\n",
    "Where:\n",
    "- Î²â‚€ = intercept (base price)\n",
    "- Î²â‚ = coefficient (price increase per quality point)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9m3nr1docpp",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T07:49:56.857277Z",
     "iopub.status.busy": "2025-11-23T07:49:56.856915Z",
     "iopub.status.idle": "2025-11-23T07:49:56.869601Z",
     "shell.execute_reply": "2025-11-23T07:49:56.868222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—ï¸ Building Simple Linear Regression Model:\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (2344, 1)\n",
      "Testing data shape: (586, 1)\n",
      "\n",
      "âœ… Model Trained Successfully!\n",
      "\n",
      "ğŸ“Š Model Parameters:\n",
      "   Intercept (Î²â‚€): $-89,311.54\n",
      "   Coefficient (Î²â‚) for Overall Qual: $44,174.67\n",
      "\n",
      "ğŸ’¡ Interpretation:\n",
      "   Base Price: $-89,312\n",
      "   For each 1-point increase in Overall Qual:\n",
      "      â†’ Price increases by $44,175\n",
      "\n",
      "ğŸ“‹ Example: A house with Overall Qual = 7\n",
      "   Predicted Price: $219,911\n"
     ]
    }
   ],
   "source": [
    "# Step 7b: Build and train Simple Linear Regression model\n",
    "print(\"ğŸ—ï¸ Building Simple Linear Regression Model:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Prepare data with only the best feature (Overall Qual)\n",
    "X_train_simple = X_train[[best_feature]]  # Must be 2D array for sklearn\n",
    "X_test_simple = X_test[[best_feature]]\n",
    "\n",
    "print(f\"Training data shape: {X_train_simple.shape}\")\n",
    "print(f\"Testing data shape: {X_test_simple.shape}\")\n",
    "\n",
    "# Create and train the model\n",
    "simple_lr = LinearRegression()\n",
    "simple_lr.fit(X_train_simple, y_train)\n",
    "\n",
    "print(f\"\\nâœ… Model Trained Successfully!\")\n",
    "print(f\"\\nğŸ“Š Model Parameters:\")\n",
    "print(f\"   Intercept (Î²â‚€): ${simple_lr.intercept_:,.2f}\")\n",
    "print(f\"   Coefficient (Î²â‚) for {best_feature}: ${simple_lr.coef_[0]:,.2f}\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ Interpretation:\")\n",
    "print(f\"   Base Price: ${simple_lr.intercept_:,.0f}\")\n",
    "print(f\"   For each 1-point increase in {best_feature}:\")\n",
    "print(f\"      â†’ Price increases by ${simple_lr.coef_[0]:,.0f}\")\n",
    "\n",
    "# Example prediction\n",
    "example_quality = 7  # Average quality house\n",
    "example_price = simple_lr.intercept_ + simple_lr.coef_[0] * example_quality\n",
    "print(f\"\\nğŸ“‹ Example: A house with {best_feature} = {example_quality}\")\n",
    "print(f\"   Predicted Price: ${example_price:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "l2l8lcf4oi",
   "metadata": {},
   "source": [
    "### ğŸ“Š Step 7c: Evaluate Simple Linear Regression Performance\n",
    "\n",
    "**What we're evaluating**:\n",
    "- **RÂ² Score**: How much variance in price our model explains (0 to 1)\n",
    "- **RMSE**: Average prediction error in dollars (lower is better)\n",
    "- **MAE**: Average absolute error in dollars (lower is better)\n",
    "\n",
    "**Evaluation on**: Both training set (to check fit) and testing set (to check generalization)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dpawz2bdsbh",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T07:49:56.873097Z",
     "iopub.status.busy": "2025-11-23T07:49:56.872630Z",
     "iopub.status.idle": "2025-11-23T07:49:56.893953Z",
     "shell.execute_reply": "2025-11-23T07:49:56.892253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Evaluating Simple Linear Regression Model:\n",
      "======================================================================\n",
      "ğŸ“ˆ TRAINING SET Performance:\n",
      "   RÂ² Score    : 0.6325 (63.25% variance explained)\n",
      "   RMSE        : $46,744.71\n",
      "   MAE         : $32,962.20\n",
      "\n",
      "ğŸ“‰ TESTING SET Performance:\n",
      "   RÂ² Score    : 0.6512 (65.12% variance explained)\n",
      "   RMSE        : $52,878.68\n",
      "   MAE         : $36,141.27\n",
      "\n",
      "ğŸ” Model Assessment:\n",
      "   RÂ² difference (train - test): 0.0187\n",
      "   âœ… Good generalization! Model performs similarly on unseen data.\n",
      "\n",
      "ğŸ’¡ Interpretation:\n",
      "   On average, predictions are off by $36,141\n",
      "   The model explains 65.1% of price variance using just ONE feature!\n"
     ]
    }
   ],
   "source": [
    "# Step 7c: Evaluate Simple Linear Regression model\n",
    "print(\"ğŸ“Š Evaluating Simple Linear Regression Model:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Make predictions on training set\n",
    "y_train_pred_simple = simple_lr.predict(X_train_simple)\n",
    "\n",
    "# Make predictions on testing set\n",
    "y_test_pred_simple = simple_lr.predict(X_test_simple)\n",
    "\n",
    "# Calculate metrics for TRAINING set\n",
    "train_r2_simple = r2_score(y_train, y_train_pred_simple)\n",
    "train_rmse_simple = np.sqrt(mean_squared_error(y_train, y_train_pred_simple))\n",
    "train_mae_simple = mean_absolute_error(y_train, y_train_pred_simple)\n",
    "\n",
    "# Calculate metrics for TESTING set\n",
    "test_r2_simple = r2_score(y_test, y_test_pred_simple)\n",
    "test_rmse_simple = np.sqrt(mean_squared_error(y_test, y_test_pred_simple))\n",
    "test_mae_simple = mean_absolute_error(y_test, y_test_pred_simple)\n",
    "\n",
    "print(f\"ğŸ“ˆ TRAINING SET Performance:\")\n",
    "print(f\"   RÂ² Score    : {train_r2_simple:.4f} ({train_r2_simple*100:.2f}% variance explained)\")\n",
    "print(f\"   RMSE        : ${train_rmse_simple:,.2f}\")\n",
    "print(f\"   MAE         : ${train_mae_simple:,.2f}\")\n",
    "\n",
    "print(f\"\\nğŸ“‰ TESTING SET Performance:\")\n",
    "print(f\"   RÂ² Score    : {test_r2_simple:.4f} ({test_r2_simple*100:.2f}% variance explained)\")\n",
    "print(f\"   RMSE        : ${test_rmse_simple:,.2f}\")\n",
    "print(f\"   MAE         : ${test_mae_simple:,.2f}\")\n",
    "\n",
    "# Check for overfitting/underfitting\n",
    "r2_diff = abs(train_r2_simple - test_r2_simple)\n",
    "print(f\"\\nğŸ” Model Assessment:\")\n",
    "print(f\"   RÂ² difference (train - test): {r2_diff:.4f}\")\n",
    "if r2_diff < 0.05:\n",
    "    print(f\"   âœ… Good generalization! Model performs similarly on unseen data.\")\n",
    "elif r2_diff < 0.10:\n",
    "    print(f\"   âš ï¸ Acceptable generalization with slight overfitting.\")\n",
    "else:\n",
    "    print(f\"   âš ï¸ Significant overfitting detected!\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ Interpretation:\")\n",
    "print(f\"   On average, predictions are off by ${test_mae_simple:,.0f}\")\n",
    "print(f\"   The model explains {test_r2_simple*100:.1f}% of price variance using just ONE feature!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "msh4veldt8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 8: Multiple Linear Regression Model\n",
    "\n",
    "### ğŸ¯ What are we doing?\n",
    "Building a **Multiple Linear Regression** model using **ALL 66 features** to predict house prices.\n",
    "\n",
    "### ğŸ¤” Why Multiple Linear Regression?\n",
    "- Uses **ALL available information** (66 features vs just 1)\n",
    "- Captures complex relationships between multiple factors\n",
    "- Expected to perform better than Simple LR\n",
    "- More realistic for real-world predictions\n",
    "\n",
    "### ğŸ“Š Expected Result:\n",
    "- Use all 66 features simultaneously\n",
    "- Expected RÂ² > 0.70 (better than Simple LR's 0.65)\n",
    "- Lower prediction error (MAE)\n",
    "- More accurate price predictions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "rppehytx7cs",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T07:49:56.897335Z",
     "iopub.status.busy": "2025-11-23T07:49:56.896692Z",
     "iopub.status.idle": "2025-11-23T07:49:56.925202Z",
     "shell.execute_reply": "2025-11-23T07:49:56.921894Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—ï¸ Building Multiple Linear Regression Model:\n",
      "======================================================================\n",
      "Using ALL features:\n",
      "   Training data shape: (2344, 66)\n",
      "   Testing data shape: (586, 66)\n",
      "   Total features: 66\n",
      "\n",
      "âœ… Model Trained Successfully!\n",
      "\n",
      "ğŸ“Š Model Parameters:\n",
      "   Intercept (Î²â‚€): $2,623,545.75\n",
      "   Number of coefficients: 66\n",
      "\n",
      "ğŸ“Š Top 10 Most Influential Features:\n",
      "======================================================================\n",
      "   Overall Qual              : $   12,305.28\n",
      "   Garage Cars               : $   11,206.05\n",
      "   Exter Qual                : $   10,175.53\n",
      "   Kitchen Qual              : $    9,857.35\n",
      "   Kitchen AbvGr             : $   -8,687.59\n",
      "   Bsmt Cond                 : $   -7,943.73\n",
      "   Bsmt Qual                 : $    7,647.23\n",
      "   Overall Cond              : $    4,999.49\n",
      "   Fireplaces                : $    4,957.09\n",
      "   Bsmt Exposure             : $   -4,154.57\n",
      "\n",
      "ğŸ’¡ These features have the largest impact on price predictions\n"
     ]
    }
   ],
   "source": [
    "# Step 8a: Build and train Multiple Linear Regression model\n",
    "print(\"ğŸ—ï¸ Building Multiple Linear Regression Model:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"Using ALL features:\")\n",
    "print(f\"   Training data shape: {X_train.shape}\")\n",
    "print(f\"   Testing data shape: {X_test.shape}\")\n",
    "print(f\"   Total features: {X_train.shape[1]}\")\n",
    "\n",
    "# Create and train the model\n",
    "multiple_lr = LinearRegression()\n",
    "multiple_lr.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nâœ… Model Trained Successfully!\")\n",
    "print(f\"\\nğŸ“Š Model Parameters:\")\n",
    "print(f\"   Intercept (Î²â‚€): ${multiple_lr.intercept_:,.2f}\")\n",
    "print(f\"   Number of coefficients: {len(multiple_lr.coef_)}\")\n",
    "\n",
    "# Show top 5 most influential features (by absolute coefficient value)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Coefficient': multiple_lr.coef_\n",
    "})\n",
    "feature_importance['Abs_Coefficient'] = feature_importance['Coefficient'].abs()\n",
    "feature_importance = feature_importance.sort_values('Abs_Coefficient', ascending=False)\n",
    "\n",
    "print(f\"\\nğŸ“Š Top 10 Most Influential Features:\")\n",
    "print(\"=\"*70)\n",
    "for i, row in feature_importance.head(10).iterrows():\n",
    "    print(f\"   {row['Feature']:25s} : ${row['Coefficient']:>12,.2f}\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ These features have the largest impact on price predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9z7lig5ibzc",
   "metadata": {},
   "source": [
    "### ğŸ“Š Step 8b: Evaluate Multiple Linear Regression Performance\n",
    "\n",
    "**Evaluating**: Same metrics as Simple LR for direct comparison\n",
    "- RÂ² Score (variance explained)\n",
    "- RMSE (root mean squared error)\n",
    "- MAE (mean absolute error)\n",
    "\n",
    "**Goal**: Multiple LR should outperform Simple LR by using all available features\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7y1u3z01fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T07:49:56.927972Z",
     "iopub.status.busy": "2025-11-23T07:49:56.927664Z",
     "iopub.status.idle": "2025-11-23T07:49:56.946936Z",
     "shell.execute_reply": "2025-11-23T07:49:56.945878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Evaluating Multiple Linear Regression Model:\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ˆ TRAINING SET Performance:\n",
      "   RÂ² Score    : 0.8607 (86.07% variance explained)\n",
      "   RMSE        : $28,778.82\n",
      "   MAE         : $18,341.38\n",
      "\n",
      "ğŸ“‰ TESTING SET Performance:\n",
      "   RÂ² Score    : 0.8579 (85.79% variance explained)\n",
      "   RMSE        : $33,755.05\n",
      "   MAE         : $20,928.19\n",
      "\n",
      "ğŸ” Model Assessment:\n",
      "   RÂ² difference (train - test): 0.0028\n",
      "   âœ… Good generalization! Model performs similarly on unseen data.\n",
      "\n",
      "ğŸ’¡ Interpretation:\n",
      "   On average, predictions are off by $20,928\n",
      "   The model explains 85.8% of price variance using ALL 66 features!\n"
     ]
    }
   ],
   "source": [
    "# Step 8b: Evaluate Multiple Linear Regression model\n",
    "print(\"ğŸ“Š Evaluating Multiple Linear Regression Model:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Make predictions on training set\n",
    "y_train_pred_multiple = multiple_lr.predict(X_train)\n",
    "\n",
    "# Make predictions on testing set\n",
    "y_test_pred_multiple = multiple_lr.predict(X_test)\n",
    "\n",
    "# Calculate metrics for TRAINING set\n",
    "train_r2_multiple = r2_score(y_train, y_train_pred_multiple)\n",
    "train_rmse_multiple = np.sqrt(mean_squared_error(y_train, y_train_pred_multiple))\n",
    "train_mae_multiple = mean_absolute_error(y_train, y_train_pred_multiple)\n",
    "\n",
    "# Calculate metrics for TESTING set\n",
    "test_r2_multiple = r2_score(y_test, y_test_pred_multiple)\n",
    "test_rmse_multiple = np.sqrt(mean_squared_error(y_test, y_test_pred_multiple))\n",
    "test_mae_multiple = mean_absolute_error(y_test, y_test_pred_multiple)\n",
    "\n",
    "print(f\"ğŸ“ˆ TRAINING SET Performance:\")\n",
    "print(f\"   RÂ² Score    : {train_r2_multiple:.4f} ({train_r2_multiple*100:.2f}% variance explained)\")\n",
    "print(f\"   RMSE        : ${train_rmse_multiple:,.2f}\")\n",
    "print(f\"   MAE         : ${train_mae_multiple:,.2f}\")\n",
    "\n",
    "print(f\"\\nğŸ“‰ TESTING SET Performance:\")\n",
    "print(f\"   RÂ² Score    : {test_r2_multiple:.4f} ({test_r2_multiple*100:.2f}% variance explained)\")\n",
    "print(f\"   RMSE        : ${test_rmse_multiple:,.2f}\")\n",
    "print(f\"   MAE         : ${test_mae_multiple:,.2f}\")\n",
    "\n",
    "# Check for overfitting/underfitting\n",
    "r2_diff_multiple = abs(train_r2_multiple - test_r2_multiple)\n",
    "print(f\"\\nğŸ” Model Assessment:\")\n",
    "print(f\"   RÂ² difference (train - test): {r2_diff_multiple:.4f}\")\n",
    "if r2_diff_multiple < 0.05:\n",
    "    print(f\"   âœ… Good generalization! Model performs similarly on unseen data.\")\n",
    "elif r2_diff_multiple < 0.10:\n",
    "    print(f\"   âš ï¸ Acceptable generalization with slight overfitting.\")\n",
    "else:\n",
    "    print(f\"   âš ï¸ Significant overfitting detected!\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ Interpretation:\")\n",
    "print(f\"   On average, predictions are off by ${test_mae_multiple:,.0f}\")\n",
    "print(f\"   The model explains {test_r2_multiple*100:.1f}% of price variance using ALL 66 features!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iozv3spqsz",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 9: Model Comparison & Final Results\n",
    "\n",
    "### ğŸ¯ What are we comparing?\n",
    "Side-by-side comparison of **Simple LR** vs **Multiple LR** performance\n",
    "\n",
    "### ğŸ“Š Key Questions:\n",
    "1. How much does using all features improve performance?\n",
    "2. Which model generalizes better to unseen data?\n",
    "3. What's the practical impact on prediction accuracy?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7x7d1jbnb8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-23T07:49:56.949855Z",
     "iopub.status.busy": "2025-11-23T07:49:56.949533Z",
     "iopub.status.idle": "2025-11-23T07:49:56.963473Z",
     "shell.execute_reply": "2025-11-23T07:49:56.961929Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š MODEL COMPARISON: Simple LR vs Multiple LR\n",
      "================================================================================\n",
      "       Metric        Simple LR Multiple LR\n",
      "Features Used 1 (Overall Qual)    66 (All)\n",
      "   RÂ² (Train)           0.6325      0.8607\n",
      "    RÂ² (Test)           0.6512      0.8579\n",
      "  RMSE (Test)          $52,879     $33,755\n",
      "   MAE (Test)          $36,141     $20,928\n",
      "RÂ² Difference           0.0187      0.0028\n",
      "\n",
      "\n",
      "ğŸ¯ KEY FINDINGS:\n",
      "================================================================================\n",
      "âœ… RÂ² Improvement: 0.2066 (20.66% more variance explained)\n",
      "âœ… MAE Improvement: $15,213 (42.1% reduction in error)\n",
      "âœ… Both models show EXCELLENT generalization (low train-test difference)\n",
      "\n",
      "\n",
      "ğŸ’¡ INTERPRETATION:\n",
      "================================================================================\n",
      "1. Simple LR (1 feature):\n",
      "   - Using ONLY 'Overall Qual', achieves RÂ² = 0.6512\n",
      "   - Proves quality ratings are the strongest price predictor\n",
      "   - Average error: $36,141\n",
      "\n",
      "2. Multiple LR (66 features):\n",
      "   - Using ALL available features, achieves RÂ² = 0.8579\n",
      "   - Explains 85.8% of price variance!\n",
      "   - Average error: $20,928\n",
      "   - Reduces prediction error by $15,213 compared to Simple LR\n",
      "\n",
      "\n",
      "ğŸ† WINNER: Multiple Linear Regression\n",
      "================================================================================\n",
      "Multiple LR is the CLEAR WINNER:\n",
      "  â€¢ 20.7% better at explaining price variance\n",
      "  â€¢ $15,213 lower average prediction error\n",
      "  â€¢ Still maintains excellent generalization to new data\n",
      "  â€¢ Ready for production use in price prediction!\n",
      "\n",
      "âœ… Phase 3 Complete! Both models successfully built and evaluated.\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Model Comparison\n",
    "print(\"ğŸ“Š MODEL COMPARISON: Simple LR vs Multiple LR\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison = pd.DataFrame({\n",
    "    'Metric': ['Features Used', 'RÂ² (Train)', 'RÂ² (Test)', 'RMSE (Test)', 'MAE (Test)', 'RÂ² Difference'],\n",
    "    'Simple LR': [\n",
    "        f'1 ({best_feature})',\n",
    "        f'{train_r2_simple:.4f}',\n",
    "        f'{test_r2_simple:.4f}',\n",
    "        f'${test_rmse_simple:,.0f}',\n",
    "        f'${test_mae_simple:,.0f}',\n",
    "        f'{abs(train_r2_simple - test_r2_simple):.4f}'\n",
    "    ],\n",
    "    'Multiple LR': [\n",
    "        f'66 (All)',\n",
    "        f'{train_r2_multiple:.4f}',\n",
    "        f'{test_r2_multiple:.4f}',\n",
    "        f'${test_rmse_multiple:,.0f}',\n",
    "        f'${test_mae_multiple:,.0f}',\n",
    "        f'{abs(train_r2_multiple - test_r2_multiple):.4f}'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "# Calculate improvements\n",
    "r2_improvement = test_r2_multiple - test_r2_simple\n",
    "mae_improvement = test_mae_simple - test_mae_multiple\n",
    "mae_improvement_pct = (mae_improvement / test_mae_simple) * 100\n",
    "\n",
    "print(f\"\\n\\nğŸ¯ KEY FINDINGS:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"âœ… RÂ² Improvement: {r2_improvement:.4f} ({r2_improvement*100:.2f}% more variance explained)\")\n",
    "print(f\"âœ… MAE Improvement: ${mae_improvement:,.0f} ({mae_improvement_pct:.1f}% reduction in error)\")\n",
    "print(f\"âœ… Both models show EXCELLENT generalization (low train-test difference)\")\n",
    "\n",
    "print(f\"\\n\\nğŸ’¡ INTERPRETATION:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"1. Simple LR (1 feature):\")\n",
    "print(f\"   - Using ONLY 'Overall Qual', achieves RÂ² = {test_r2_simple:.4f}\")\n",
    "print(f\"   - Proves quality ratings are the strongest price predictor\")\n",
    "print(f\"   - Average error: ${test_mae_simple:,.0f}\")\n",
    "\n",
    "print(f\"\\n2. Multiple LR (66 features):\")\n",
    "print(f\"   - Using ALL available features, achieves RÂ² = {test_r2_multiple:.4f}\")\n",
    "print(f\"   - Explains {test_r2_multiple*100:.1f}% of price variance!\")\n",
    "print(f\"   - Average error: ${test_mae_multiple:,.0f}\")\n",
    "print(f\"   - Reduces prediction error by ${mae_improvement:,.0f} compared to Simple LR\")\n",
    "\n",
    "print(f\"\\n\\nğŸ† WINNER: Multiple Linear Regression\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Multiple LR is the CLEAR WINNER:\")\n",
    "print(f\"  â€¢ {r2_improvement*100:.1f}% better at explaining price variance\")\n",
    "print(f\"  â€¢ ${mae_improvement:,.0f} lower average prediction error\")\n",
    "print(f\"  â€¢ Still maintains excellent generalization to new data\")\n",
    "print(f\"  â€¢ Ready for production use in price prediction!\")\n",
    "\n",
    "print(f\"\\nâœ… Phase 3 Complete! Both models successfully built and evaluated.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
